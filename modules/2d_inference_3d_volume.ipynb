{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c408367e",
      "metadata": {
        "id": "c408367e"
      },
      "source": [
        "Copyright (c) MONAI Consortium  \n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
        "you may not use this file except in compliance with the License.  \n",
        "You may obtain a copy of the License at  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
        "Unless required by applicable law or agreed to in writing, software  \n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
        "See the License for the specific language governing permissions and  \n",
        "limitations under the License.\n",
        "\n",
        "# 2D Model Inference on a 3D Volume  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8681db2",
      "metadata": {
        "id": "a8681db2"
      },
      "source": [
        "Usecase: A 2D Model, such as, a 2D segmentation U-Net operates on 2D input which can be slices from a 3D volume (for example, a CT scan).\n",
        "\n",
        "After editing sliding window inferer as described in this tutorial, it can handle the entire flow as shown:\n",
        "![image](https://github.com/Project-MONAI/tutorials/blob/main/figures/2d_inference_3d_input.png?raw=1)\n",
        "\n",
        "The input is a *3D Volume*, a *2D model* and the output is a *3D volume* with 2D slice predictions aggregated.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/modules/2d_inference_3d_volume.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3a44a5",
      "metadata": {
        "id": "5c3a44a5"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f2e1b91f",
      "metadata": {
        "id": "f2e1b91f",
        "outputId": "c5965c72-5559-4db1-c4f0-49fb074c95ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-25 01:20:58.440718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-25 01:20:58.463292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-25 01:20:58.470474: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-25 01:20:58.487863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-25 01:20:59.848112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[tqdm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81870a3",
      "metadata": {
        "id": "a81870a3"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e9cd1b08",
      "metadata": {
        "id": "e9cd1b08",
        "outputId": "3be83890-de10-4540-c0ce-100529a539f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.5.dev2451\n",
            "Numpy version: 1.26.4\n",
            "Pytorch version: 2.5.1+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 7c1c58cd10db72c01b5cdda1600cd68e262437cf\n",
            "MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.25.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 11.0.0\n",
            "Tensorboard version: 2.17.1\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.1+cu121\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.2.2\n",
            "einops version: 0.8.0\n",
            "transformers version: 4.47.1\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from monai.config import print_config\n",
        "from monai.inferers import SliceInferer\n",
        "from monai.networks.nets import UNet\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f00a47",
      "metadata": {
        "id": "85f00a47"
      },
      "source": [
        "## SliceInferer\n",
        "The simplest way to achieve this functionality is to extend the `SlidingWindowInferer` in `monai.inferers`. This is made available as `SliceInferer` in MONAI (https://docs.monai.io/en/latest/inferers.html#sliceinferer)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0a63dd",
      "metadata": {
        "id": "bb0a63dd"
      },
      "source": [
        "## Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "85b15305",
      "metadata": {
        "id": "85b15305",
        "outputId": "eb8fdbcc-39b3-4bb9-f746-4f0c1feb4372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [00:01<00:00, 33.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Axial Inferer Output Shape:  torch.Size([1, 1, 64, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 256/256 [00:01<00:00, 129.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coronal Inferer Output Shape:  torch.Size([1, 1, 64, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a 2D UNet with randomly initialized weights for testing purposes\n",
        "\n",
        "# 3 layer network with down/upsampling by a factor of 2 at each layer with 2-convolution residual units\n",
        "net = UNet(\n",
        "    spatial_dims=2,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(4, 8, 16),\n",
        "    strides=(2, 2),\n",
        "    num_res_units=2,\n",
        ")\n",
        "\n",
        "# Initialize a dummy 3D tensor volume with shape (N,C,D,H,W)\n",
        "input_volume = torch.ones(1, 1, 64, 256, 256)\n",
        "\n",
        "# Create an instance of SliceInferer with roi_size as the 256x256 (HxW) and sliding over D axis\n",
        "axial_inferer = SliceInferer(roi_size=(256, 256), sw_batch_size=1, cval=-1, progress=True)\n",
        "\n",
        "output = axial_inferer(input_volume, net)\n",
        "\n",
        "# Output is a 3D volume with 2D slices aggregated\n",
        "print(\"Axial Inferer Output Shape: \", output.shape)\n",
        "# Create an instance of SliceInferer with roi_size as the 64x256 (DxW) and sliding over H axis\n",
        "coronal_inferer = SliceInferer(\n",
        "    roi_size=(64, 256),\n",
        "    sw_batch_size=1,\n",
        "    spatial_dim=1,  # Spatial dim to slice along is added here\n",
        "    cval=-1,\n",
        "    progress=True,\n",
        ")\n",
        "\n",
        "output = coronal_inferer(input_volume, net)\n",
        "\n",
        "# Output is a 3D volume with 2D slices aggregated\n",
        "print(\"Coronal Inferer Output Shape: \", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2596d86",
      "metadata": {
        "id": "f2596d86"
      },
      "source": [
        "Note that with `axial_inferer` and `coronal_inferer`, the number of inference iterations is 64 and 256 respectively."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}